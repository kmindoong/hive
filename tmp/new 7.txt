/*
https://github.com/kmindoong/hive

-- 참고
https://github.com/rcongiu/Hive-JSON-Serde

-- 모니터링
http://sandbox-hdp.hortonworks.com:8080

-- 참고
https://aws.amazon.com/ko/documentation/

http://chess72.tistory.com

-- process kill 
yarn application -kill

-- 파일을 지웠을경우 휴지통 위치
user/hdfs/.Trash/Current/

*/


	create table hive_edu.iris3
	(sepal_len FLOAT,
	sepal_width FLOAT,
	petal_len FLOAT,
	response STRING)
	ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
	LINES TERMINATED BY '\n'
	STORED AS TEXTFILE
	tblproperties ("skip.header.line.count"="1");


	- Database 명 : hive_test
	- Table 명 : hive_exec_01
	- Table Data Location : hive_exec_01 의 default 위치
	- Column 정보 : birth (string), name(string)

		- 데이터 : 본인 생년월일, 이름의 CSV 형식으로 각자 생성
	(ex. 801225, 홍길동)
	- 데이터 구분자 : , (콤마)
	- 결과 : select * from hive_exec_01; 의 쿼리가 정상적으로 나오면 OK

	-------------------

	CREATE DATABASE IF NOT EXISTS hive_test

	CREATE TABLE hive_test.hive_exec_01 (
	 birth string,
	 name string ) 
	 ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' 
	 LINES TERMINATED BY '\n'
	 STORED AS TEXTFILE
	;


	hadoop fs -copyFromLocal hive_exec_01.csv /apps/hive/warehouse/hive_test.db/hive_exec_01/hive_exec_01.data


	fs -put test.csv /apps/hive/warehouse/hive_test.db/hive_exec_01/.

	
	--------------------
	
	CREATE TABLE sales (
	sales_order_id BIGINT,
	order_amount FLOAT,
	order_date STRING,
	due_date STRING,
	customer_id BIGINT
	)
	PARTITIONED BY (country STRING, year INT, month INT, day INT)
	ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';

	hadoop fs -mkdir -p /apps/hive/warehouse/hive_edu.db/sales/kr/2015/03/03

	hadoop fs -copyFromLocal ./1_test.dat /apps/hive/warehouse/hive_edu.db/sales/kr/2015/03/03/.


	ALTER TABLE sales ADD PARTITION (country = 'kr', year = 2015, month = 03, day = 03) 
	LOCATION '/apps/hive/warehouse/hive_edu.db/sales/kr/2015/03/03';

	---------------------------------------------------


	CREATE TABLE hive_exec_02 (
	sales_order_id BIGINT,
	order_amount FLOAT,
	order_date STRING,
	due_date STRING,
	customer_id BIGINT
	)
	PARTITIONED BY (country STRING, yyyymmd BIGINT)
	ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';

	hadoop fs -mkdir -p /apps/hive/warehouse/hive_edu.db/sales/kr/20180618

	hadoop fs -copyFromLocal ./1_test.dat /apps/hive/warehouse/hive_edu.db/sales/kr/20180618


	LOCATION '/apps/hive/warehouse/hive_edu.db/sales/kr/2015/03/03';
	ALTER TABLE sales ADD PARTITION (country = 'kr', yyyymmd = '20180618;) 

	
	

	--------------------
	
LOAD DATA LOCAL INPATH '/home/hdfs/hive/sample_file/airport.dat' INTO 
TABLE hive_edu.airport;

LOAD DATA LOCAL INPATH '/home/hdfs/hive/sample_file/airline.dat' INTO
TABLE hive_edu.airline;

# INNER JOIN 실습 (3개 테이블)
• HDFS 디렉토리 생성
• $ hadoop fs -mkdir -p /tmp/table/card
• $ hadoop fs -mkdir -p /tmp/table/user
• $ hadoop fs -mkdir -p /tmp/table/merchant
• 파일 업로드(HDFS)
• $ hadoop fs -put card.csv /tmp/table/card
• $ hadoop fs -put user.csv /tmp/table/user
• $ hadoop fs -put merchant.csv /tmp/table/merchant


# INNER JOIN 실습 (3개 테이블)
• 테이블 생성
• $ hive -f 1_create_table_3.hql
• 테이블 조인
• 업소별 카드 승인 금액 (CARD_HISTORY, MERCHANT)
• 성, 연령별 카드 승인 금액 (CARD_HISTORY, USERS)
• 2_join_table.hql 확인
• 3_join_table.hql 확인
• 결과를 파일로 바로 받고싶을 때?
• 1) hive –f xxx.hql > aaa.txt
• 2) CREATE TABLE IF NOT EXISTS STATISTICS AS SELECT
• hadoop fs –get ~





select a.*
from card_history a
left outer join merchant b on a.merchant_id = b.merchant_id

select b.sex, b.age, sum(a.amount)
from card_history a join users b on (a.card_owner = b.user_id)
group by b.sex, b.age;


=============================
-- 2018.06.19
=============================

-- jar 파일안의 내용을 확인할때 
jar -xvf aa.jar


-- 교재
hive> describe function udf_lastday;

CREATE TEMPORARY FUNCTION udf_LastDay as 'com.nexr.platform.hive.udf.UDFLastDay';


-- 1.실습
hive> add jar /home/hdfs/hive/nexr-hive-udf-0.2-SNAPSHOT.jar;
hive> CREATE TEMPORARY FUNCTION udf_sysdate as 'com.nexr.platform.hive.udf.UDFSysDate';


-- 2. view실습
create view if not exists v_airport as select year,month,airtime
from airport limit 10;


-- 3. view실습 p131
hive -f 1_create_rcfile_raw_table.hql

hive -f 2_create_rcfile_columnar_table.hql

hadoop fs -copyFromLocal ./rcfile.dat /hive_edu/rcfile_raw/.

hive -f 3_insert_rcfile.hql

select * from rcfile_columnar;

dfs -cat /hive_edu/rcfile_columnar/000000_0;

hive --service rcfilecat /hive_edu/rcfile_columnar/000000_0


-- 4. view실습 p135
hive -f 1_create_orcfile_columnar_table.hql

hive -f 2_insert_orcfile.hql

select * from hive_edu.orcfile_columnar limit 10;

hadoop fs -ls /hive_edu/orcfile_columnar


------------------------------



hadoop fs -mkdir -p /tmp/test/data

-- test.json을 아래 경로로 복사
hadoop fs -put test.json /tmp/test/data/.


---------------------------

-- 5. JSON SerDe 실습 p138 

hive>add jar /home/hdfs/hive/example/4/json-serde-1.3.8-jar-with-dependencies.jar;

CREATE TABLE example
(
one boolean,
three array<string>,
two double,
four string
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
STORED AS TEXTFILE;


> LOAD DATA LOCAL INPATH '/home/hdfs/hive/example/4/example.json'
overwrite into table example;


----------------

-- p152
sqoop import-all-tables \
--connect jdbc:mysql://mysql.example.com/mydb \
--username sqoop \
--password sqoop \

--2개 테이블 제외
--exclude-tables cities,countries \
--warehouse-dir /teststore/input/




-- 6. Sqoop 실습 p160

	− CARD_HISTORY, MERCHANT JOIN 
	=> 카테고리별 카드승인 총금액(statistics_by_business_type) 테이블 생성
	후 SQOOP EXPORT직접 명령어를 만들어서 해보세요


	[hdfs@sandbox-hdp hive]$ mysql -u root -p
	Enter password:hadoop

	------------

	-- 방법1
	hive (hive_edu)> create table statistics_by_business_type(
	business_type string,
	sum_amount float
	);
	
	hive (hive_edu)> insert into table statistics_by_business_type
	select b.business_type
	 , sum(a.amount)
	from card_history a
	 join merchant b
	 on a.merchant_id = b.merchant_id
	group by b.business_type;


	-- 방법2
	hive (hive_edu)> create table if not exists statistics_by_business_type_new
	ROW FORMAT DELIMITED FIELDS TERMINATED BY ','  -- 구분자를 줘야 된다.
	as
	select b.business_type
	 , sum(a.amount)
	from card_history a
	 join merchant b
	 on a.merchant_id = b.merchant_id
	group by b.business_type;


	* mysql에 테이블 생성

		mysql> use hive;
		Reading table information for completion of table and column names
		You can turn off this feature to get a quicker startup with -A

		Database changed
		mysql> show databases;
		+--------------------+
		| Database           |
		+--------------------+
		| information_schema |
		| hive               |
		| mysql              |
		| performance_schema |
		| ranger             |
		+--------------------+
		5 rows in set (0.00 sec)

		mysql> create table statistics_by_business_type(
			-> business_type varchar(100),
			-> sum_amount int
			-> );
		Query OK, 0 rows affected (0.01 sec)

		mysql> select * from statistics_by_business_type;
		Empty set (0.00 sec)


	sqoop export \
	--connect jdbc:mysql://sandbox-hdp.hortonworks.com/hive \
	--username root \
	--password hadoop \
	--table statistics_by_business_type \
	--export-dir /apps/hive/warehouse/hive_edu.db/statistics_by_business_type_new

		-- 확인
		mysql> select * from statistics_by_business_type;
		+---------------+------------+
		| business_type | sum_amount |
		+---------------+------------+
		| Mart          |     102200 |
		| Restaurant    |     144600 |
		| Beer          |      68700 |
		| Hair Salon    |       9600 |
		| Hospital      |      93600 |
		+---------------+------------+
		5 rows in set (0.00 sec)



-- 7. Sqoop 실습 p170

	CREATE INDEX idx_01_airport
	ON TABLE airport (year, month, flightnum)
	AS 'COMPACT'
	WITH DEFERRED REBUILD;

	-- 에러발생(원인 tez에서는 index지원하지않는다.)
	Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. 
	Indexes unsupported for Tez execution engine

	-- 해결방법 : 해당 세션에서는 mr사용으로 함
	set hive.execution.engine=mr;


	CREATE INDEX idx_02_port
	ON TABLE airport (flightnum)
	AS 'BITMAP'
	WITH DEFERRED REBUILD;


	CREATE INDEX idx_03_port
	ON TABLE airport (flightnum)
	AS 'BITMAP'
	WITH DEFERRED REBUILD
	STORED AS RCFILE;


	show formatted index on airport;
	desc formatted hive_edu__airport_idx_01_airport__;
	
	-- 실습 8 p185
		
	CREATE TABLE airline_comp_gz_snappy_seq
	ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
	STORED AS SEQUENCEFILE
	AS SELECT * FROM airline;
		
	hadoop fs -ls /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq

	hadoop fs -text /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq/000000_0
		
		
	-- 테이블에 데이터가 쌓일때 내용을 압축한다.
	hive (hive_edu)> set hive.exec.compress.output=true;
	hive (hive_edu)> CREATE TABLE airline_comp_gz_snappy_seq2
				   > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
				   > STORED AS SEQUENCEFILE
				   > AS SELECT * FROM airline;

		-- 결과 확인
	[hdfs@sandbox-hdp ~]$ hadoop fs -ls /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq
	Found 1 items
	-rwxrwxrwx   1 hdfs hadoop     392726 2018-06-19 07:01 /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq/000000_0
	[hdfs@sandbox-hdp ~]$ hadoop fs -ls /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq2
	Found 1 items
	-rwxrwxrwx   1 hdfs hadoop     132401 2018-06-19 07:02 /apps/hive/warehouse/hive_edu.db/airline_comp_gz_snappy_seq2/000000_0
	[hdfs@sandbox-hdp ~]$

	
	
	
	
	
	
	
	